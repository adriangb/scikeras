{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Run in Colab](https://www.tensorflow.org/images/colab_logo_32px.png)](https://colab.research.google.com/github/adriangb/scikeras/blob/master/docs/source/notebooks/Basic_Usage.ipynb) Run in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22BE9uhvoxO"
   },
   "source": [
    "# Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hapoJed-voxP"
   },
   "source": [
    "`SciKeras` is designed to maximize interoperability between `sklearn` and `Keras/TensorFlow`. The aim is to keep 99% of the flexibility of `Keras` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `SciKeras` and how it can be combined with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TxAk7fTvoxP"
   },
   "source": [
    "This notebook shows you how to use the basic functionality of `SciKeras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iT-ibpi7voxQ"
   },
   "source": [
    "### Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekJWKPFMvoxR"
   },
   "source": [
    "* [Definition of the Keras Model](#Definition-of-the-keras-model)\n",
    "* [Training a classifier](#Training-a-classifier-and-making-predictions)\n",
    "  * [Dataset](#A-toy-binary-classification-task)\n",
    "  * [Keras Model](#Definition-of-the-classification-model)\n",
    "  * [Model training](#Training-the-neural-net-classifier)\n",
    "  * [Inference](#Making-predictions,-classification)\n",
    "* [Training a regressor](#Training-a-regressor)\n",
    "  * [Dataset](#A-toy-regression-task)\n",
    "  * [Keras Model](#Definition-of-the-regression-model)\n",
    "  * [Model training](#Training-the-neural-net-regressor)\n",
    "  * [Inference](#Making-predictions,-regression)\n",
    "* [Saving and loading a model](#Saving-and-loading-a-model)\n",
    "  * [Whole model](#Saving-the-whole-model)\n",
    "  * [Only parameters](#Saving-only-the-model-parameters)\n",
    "* [Usage with an sklearn Pipeline](#Usage-with-an-sklearn-Pipeline)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Grid search](#Usage-with-sklearn-GridSearchCV)\n",
    "  * [Special prefixes](#Special-prefixes)\n",
    "  * [Performing a grid search](#Performing-a-grid-search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6avb3GBQDQyG"
   },
   "source": [
    "Install SciKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCcyTjVkvoxR"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import scikeras\n",
    "except ImportError:\n",
    "    !python -m pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZveNcetDQyL"
   },
   "source": [
    "Silence TensorFlow logging to keep output succint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ekNmO_GPDQyL"
   },
   "outputs": [],
   "source": [
    "from tensorflow import get_logger\n",
    "get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sf4j-x4DvoxV"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCuOBH8AvoxX"
   },
   "source": [
    "## Training a classifier and making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5vMC8ZYvoxY"
   },
   "source": [
    "### A toy binary classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3fAUKBUvoxY"
   },
   "source": [
    "We load a toy classification task from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmiOhALIvoxZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UQV9M0avoxc"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JuZGDyibvoxe",
    "outputId": "6ff9026f-eed7-41ef-9e26-c1de5e0597c6"
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPy_6ZDjvoxh"
   },
   "source": [
    "### Definition of the `Keras` classification `Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0BQ6Afd-voxh"
   },
   "source": [
    "We define a vanilla neural network with.\n",
    "\n",
    "Because we are dealing with 2 classes, the output layer can be constructed in\n",
    "two different ways:\n",
    "1. Single unit with a `\"sigmoid\"` nonlinearity. The loss must be `\"binary_crossentropy\"`.\n",
    "2. Two units (one for each class) and a `\"softmax\"` nonlinearity. The loss must be `\"sparse_categorical_crossentropy\"`.\n",
    "\n",
    "In this example, we choose the first option, which is what you would usually\n",
    "do for binary classification. The second option is usually reserved for when\n",
    "you have >2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS97y5OAvoxi"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6YrdtoXvoxl"
   },
   "outputs": [],
   "source": [
    "def get_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g-7ru5dvoxo"
   },
   "source": [
    "### Defining and training the neural net classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzswcGamvoxo"
   },
   "source": [
    "We use `KerasClassifier` because we're dealing with a classifcation task. The first argument should be a callable returning a `Keras.Model`, in this case, `get_clf`. As additional arguments, we pass the number of loss function (required) and the optimizer, but the later is optional. We must also pass all of the arguments to `get_clf` as keyword arguments to `KerasClassifier` if they don't have a default value in `get_clf`. Note that if you do not pass an argument to `KerasClassifier`, it will not be avilable for hyperparameter tuning. Finally, we also pass `random_state=0` for reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C83MtFdIvoxp"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AEHN7jrvoxr"
   },
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=get_clf,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    hidden_layer_sizes=(100,),\n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0uSTuc-voxu"
   },
   "source": [
    "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "V5MfyQuPvoxu",
    "outputId": "9f609152-2b48-4e0d-f8dc-1675e151969d"
   },
   "outputs": [],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjguWBwFvoxx"
   },
   "source": [
    "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKn0yjAhvoxx"
   },
   "source": [
    "### Making predictions, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "iCigf27Nvoxy",
    "outputId": "9f87d699-1e21-4f3a-ab97-09f9515f8cb2"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "ScEtja89vox1",
    "outputId": "8d15bcb5-9b98-4428-c7d3-7152e234e53b"
   },
   "outputs": [],
   "source": [
    "y_proba = clf.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HP0awysQvox4"
   },
   "source": [
    "## Training a regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDjfhVS1vox4"
   },
   "source": [
    "### A toy regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCte_weqvox5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23zcHqu0vox7"
   },
   "outputs": [],
   "source": [
    "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ZSud7CGzvox9",
    "outputId": "19247832-e197-4052-ea55-2a0d45d19397"
   },
   "outputs": [],
   "source": [
    "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9Q3et0GvoyA"
   },
   "source": [
    "### Definition of the `Keras` regression `Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3u4aUY3voyA"
   },
   "source": [
    "Again, define a vanilla neural network. The main difference is that the output layer always has a single unit and does not apply any nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSHVZaSLvoyB"
   },
   "outputs": [],
   "source": [
    "def get_reg(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8RlOmEEvoyD"
   },
   "source": [
    "### Defining and training the neural net regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-RNbMH4voyE"
   },
   "source": [
    "Training a regressor is almost the same as training a classifier. Mainly, we use `KerasRegressor` instead of `KerasClassifier` (this is the same terminology as in `sklearn`). We also change the loss function to `KerasRegressor.r_squared`. SciKeras provides this loss function because most of the `sklearn` ecosystem expects `R^2` as the loss function, but Keras does not have a default implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xls2GLLdvoyE"
   },
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i93o4AR0voyG"
   },
   "outputs": [],
   "source": [
    "reg = KerasRegressor(\n",
    "    model=get_reg,\n",
    "    loss=KerasRegressor.r_squared,\n",
    "    optimizer=\"adam\",\n",
    "    hidden_layer_sizes=(100,),\n",
    "    dropout=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "aYhLiboKvoyJ",
    "outputId": "b9fedc24-5909-43af-f8b6-f11d94dc62a0"
   },
   "outputs": [],
   "source": [
    "reg.fit(X_regr, y_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JXEjq7GvoyL"
   },
   "source": [
    "### Making predictions, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQzOT6u8voyL"
   },
   "source": [
    "You may call `predict` or `predict_proba` on the fitted model. For regressions, both methods return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "7j83fCr3voyM",
    "outputId": "13b666a5-11ce-47df-fbd7-b96fad8c3890"
   },
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_regr[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3HsAnkvvoyN"
   },
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nh9vJkhLvoyO"
   },
   "source": [
    "Save and load either the whole model by using pickle, or use Keras' specialized save methods on the `KerasClassifier.model_` or `KerasRegressor.model_` attribute that is created after fitting. You will want to use Keras' model saving utilities if any of the following apply:\n",
    "1. You wish to save only the weights or only the training configuration of your model.\n",
    "2. You wish to share your model with collaborators. Pickle is a relatively unsafe protocol and it is not recommended to share or load pickle objects publically.\n",
    "3. You care about performance, especially if doing in-memory serialization.\n",
    "\n",
    "For more information, see Keras' [saving documentation](https://www.tensorflow.org/guide/keras/save_and_serialize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLwHH8uSvoyO"
   },
   "source": [
    "### Saving the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3J714wuvoyP"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6vtJFKzvoyS"
   },
   "outputs": [],
   "source": [
    "bytes_model = pickle.dumps(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "LWcJt6U-voyU",
    "outputId": "9c442382-86b5-43c6-98cd-3142be85abb3"
   },
   "outputs": [],
   "source": [
    "new_reg = pickle.loads(bytes_model)\n",
    "new_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zToyA37WvoyV"
   },
   "source": [
    "### Saving using Keras' saving methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zI5Su_AnvoyW"
   },
   "source": [
    "This efficiently and safely saves the model to disk, including trained weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Nvy_H-jvoyW"
   },
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "reg.model_.save(\"/tmp/my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "Rmkr7_FmvoyY",
    "outputId": "f0493590-deaf-4c6e-88ef-b29d15ce8249"
   },
   "outputs": [],
   "source": [
    "# Load the model back into memory\n",
    "new_reg_model = keras.models.load_model(\"/tmp/my_model\")\n",
    "# Now we need to instantiate a new SciKeras object with this model\n",
    "# Note that we no longer pass paramters like hidden_layer_sizes, those\n",
    "# are note \"fixed\"\n",
    "reg = KerasRegressor(\n",
    "    new_reg_model,\n",
    "    loss=KerasRegressor.r_squared,\n",
    "    optimizer=\"adam\",\n",
    ")\n",
    "reg.fit(X_regr, y_regr)\n",
    "reg.predict(X_regr[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQY-WHYKvoyb"
   },
   "source": [
    "## Usage with an `sklearn Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9FYNKejvoyb"
   },
   "source": [
    "It is possible to put the `KerasClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoLLPLczvoyc"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqXE-c64voyd"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', clf),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "DpV2gbT_voyf",
    "outputId": "344c88d4-b8b0-4941-d4c3-0a5a672cdd7b"
   },
   "outputs": [],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "3CXd85UIvoyi",
    "outputId": "d6d0d8fd-d9b0-4b11-dfb5-90869378d55f"
   },
   "outputs": [],
   "source": [
    "y_proba = pipe.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsWBdbn1voyj"
   },
   "source": [
    "To save the whole pipeline, including the Keras model, use `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bJL15JWvoyk"
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YwFjnSynvoyk"
   },
   "source": [
    "Adding a new callback to the model is straightforward. Below we show how to add an `EarlyStopping` callback to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PO-BGgG_voyn"
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', patience=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-WOjFWKvoyp"
   },
   "source": [
    "We now generate a toy dataset using `sklearn.datasets.make_moons`. This dataset was chosen specifically to trigger early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzEOe28R4U2N"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eRFbt-vi4Rl6",
    "outputId": "30e66352-3d47-470f-8b44-449dac6f7bd6"
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmnYK4WTlFkr"
   },
   "source": [
    "We will first check fitting without the callback and then with. We will compare the training time and final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IbHXry8lLqI"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "m_FIvTq9voyp",
    "outputId": "b001c8b8-89f8-4b9d-f535-2e1cd1e548c1"
   },
   "outputs": [],
   "source": [
    "# First test without the callback\n",
    "clf = KerasClassifier(\n",
    "    model=get_clf,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    hidden_layer_sizes=(500,),\n",
    "    dropout=0.5,\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    fit__validation_split=0.2,\n",
    "    epochs=500,\n",
    "    verbose=False,\n",
    ")\n",
    "start = time.time()\n",
    "clf.fit(X, y)\n",
    "print(f\"Training time: {time.time() - start}\")\n",
    "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1]}\")  # get last value of last fit/partial_fit call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "wIUHrEOulU5_",
    "outputId": "05c9bd7f-795a-4bdb-f1f0-9f11514eacd7"
   },
   "outputs": [],
   "source": [
    "# Test with the callback\n",
    "clf = KerasClassifier(\n",
    "    model=get_clf,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    hidden_layer_sizes=(500,),\n",
    "    dropout=0.5,\n",
    "    metrics=[\"binary_accuracy\"],\n",
    "    fit__validation_split=0.2,\n",
    "    epochs=500,\n",
    "    verbose=False,\n",
    "    callbacks=[es]\n",
    ")\n",
    "start = time.time()\n",
    "clf.fit(X, y)\n",
    "print(f\"Training time: {time.time() - start}\")\n",
    "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1]}\")  # get last value of last fit/partial_fit call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_dtdHPSvoyu"
   },
   "source": [
    "For information on how to write custom callbacks, have a look at the \n",
    "\n",
    "---\n",
    "\n",
    "[Advanced_Usage](https://nbviewer.jupyter.org/github/adriangb/scikeras/blob/master/notebooks/Advanced_Usage.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ_-sWsNvoyv"
   },
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZytpOrjvoyv"
   },
   "source": [
    "### Special prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-KCDMhavoyv"
   },
   "source": [
    "SciKeras allows to direct access to all parameters passed to the wrapper constructors, including deeply nested routed parameters. This allows tunning of\n",
    "paramters like `hidden_layer_sizes` as well as `optimizer__learning_rate`.\n",
    "\n",
    "This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78M4fi78voyw"
   },
   "source": [
    "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZReurM2voyw"
   },
   "source": [
    "To differentiate paramters like `callbacks` which are accepted by both `tf.keras.Model.fit` and `tf.keras.Model.predict` you can add a `fit__` or `predict__` routing suffix respectively. Similar, the `model__` prefix may be used to specify that a paramter is destined only for `get_clf`/`get_reg` (or whatever callable you pass as your `model` argument).\n",
    "\n",
    "For more information on parameter routing with special prefixes, see the [Advanced Usage Docs](https://scikeras.org.readthedocs.build/en/latest/advanced.html#routed-parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABZUxcDDvoyz"
   },
   "source": [
    "### Performing a grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEBmCKMtvoyz"
   },
   "source": [
    "Below we show how to perform a grid search over the learning rate (`optimizer__lr`), the model's number of hidden layers (`model__hidden_layer_sizes`), the model's dropout rate (`model__dropout`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07M8iQFBvoy0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0UuvOLT_voy1"
   },
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=get_clf,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    optimizer__lr=0.1,\n",
    "    model__hidden_layer_sizes=(100,),\n",
    "    model__dropout=0.5,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NaBkHyBvoy3"
   },
   "source": [
    "*Note*: We set the verbosity level to zero (`verbose=False`) to prevent too much print output from being shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABVjFkmnvoy3"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'optimizer__lr': [0.05, 0.1],\n",
    "    'model__hidden_layer_sizes': [(100, ), (50, 50, ), (33, 33, 33, )],\n",
    "    'model__dropout': [0, 0.5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8MICSORvoy5"
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf, params, scoring='accuracy', n_jobs=-1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "1GQnzOsGvoy8",
    "outputId": "1d9afe71-2691-489b-9f02-a742605a9bf7"
   },
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UQHjLAoWvoy-",
    "outputId": "0c5e74e9-cc91-49af-f6a1-e04a285ad954"
   },
   "outputs": [],
   "source": [
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-ZpLtKvvoy_"
   },
   "source": [
    "Of course, we could further nest the `KerasClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `clf__model__hidden_layer_sizes`)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Basic_Usage.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
