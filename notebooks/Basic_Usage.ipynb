{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "Basic_Usage.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22BE9uhvoxO"
      },
      "source": [
        "# Basic usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hapoJed-voxP"
      },
      "source": [
        "*`SciKeras`* is designed to maximize interoperability between `sklearn` and `Keras/TensorFlow`. The aim is to keep 99% of the flexibility of `Keras` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `SciKeras` and how it can be combined with `sklearn`.\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipyn\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TxAk7fTvoxP"
      },
      "source": [
        "This notebook shows you how to use the basic functionality of `SciKeras`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT-ibpi7voxQ"
      },
      "source": [
        "### Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJWKPFMvoxR"
      },
      "source": [
        "* [Definition of the Keras Model](#Definition-of-the-keras-model)\n",
        "* [Training a classifier](#Training-a-classifier-and-making-predictions)\n",
        "  * [Dataset](#A-toy-binary-classification-task)\n",
        "  * [Keras Model](#Definition-of-the-classification-model)\n",
        "  * [Model training](#Training-the-neural-net-classifier)\n",
        "  * [Inference](#Making-predictions,-classification)\n",
        "* [Training a regressor](#Training-a-regressor)\n",
        "  * [Dataset](#A-toy-regression-task)\n",
        "  * [Keras Model](#Definition-of-the-regression-model)\n",
        "  * [Model training](#Training-the-neural-net-regressor)\n",
        "  * [Inference](#Making-predictions,-regression)\n",
        "* [Saving and loading a model](#Saving-and-loading-a-model)\n",
        "  * [Whole model](#Saving-the-whole-model)\n",
        "  * [Only parameters](#Saving-only-the-model-parameters)\n",
        "* [Usage with an sklearn Pipeline](#Usage-with-an-sklearn-Pipeline)\n",
        "* [Callbacks](#Callbacks)\n",
        "* [Grid search](#Usage-with-sklearn-GridSearchCV)\n",
        "  * [Special prefixes](#Special-prefixes)\n",
        "  * [Performing a grid search](#Performing-a-grid-search)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcyTjVkvoxR",
        "outputId": "06b4cdfe-1fac-4547-909a-a239297d3f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "!python -m pip install git+https://github.com/adriangb/scikeras.git@master"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/stsievert/scikeras.git@data-processing-api\n",
            "  Cloning https://github.com/stsievert/scikeras.git (to revision data-processing-api) to /tmp/pip-req-build-2y7pm4r1\n",
            "  Running command git clone -q https://github.com/stsievert/scikeras.git /tmp/pip-req-build-2y7pm4r1\n",
            "  Running command git checkout -b data-processing-api --track origin/data-processing-api\n",
            "  Switched to a new branch 'data-processing-api'\n",
            "  Branch 'data-processing-api' set up to track remote branch 'data-processing-api' from 'origin'.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied (use --upgrade to upgrade): scikeras==0.1.8 from git+https://github.com/stsievert/scikeras.git@data-processing-api in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from scikeras==0.1.8) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from scikeras==0.1.8) (2.3.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras==0.1.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras==0.1.8) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22.0->scikeras==0.1.8) (0.16.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (3.12.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (0.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2.0->scikeras==0.1.8) (0.35.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->scikeras==0.1.8) (50.3.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (0.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (1.7.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.2.0->scikeras==0.1.8) (3.2.0)\n",
            "Building wheels for collected packages: scikeras\n",
            "  Building wheel for scikeras (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikeras: filename=scikeras-0.1.8-cp36-none-any.whl size=24422 sha256=1d1a707f8a28b5c63f5e37aae66ba799364feff509c09d0870848438d5c3aa77\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s3cc8ljb/wheels/03/39/e0/ab362dd5af349aa37278bfc764f064100df487ad11b80d046f\n",
            "Successfully built scikeras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf4j-x4DvoxV"
      },
      "source": [
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuOBH8AvoxX"
      },
      "source": [
        "## Training a classifier and making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5vMC8ZYvoxY"
      },
      "source": [
        "### A toy binary classification task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3fAUKBUvoxY"
      },
      "source": [
        "We load a toy classification task from `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmiOhALIvoxZ"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UQV9M0avoxc"
      },
      "source": [
        "X, y = make_classification(1000, 20, n_informative=10, random_state=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JuZGDyibvoxe",
        "outputId": "ff169afe-44d7-447a-a9d6-10b7d22679b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape, y.shape, y.mean()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 20), (1000,), 0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPy_6ZDjvoxh"
      },
      "source": [
        "### Definition of the `Keras` classification `Model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BQ6Afd-voxh"
      },
      "source": [
        "We define a vanilla neural network with.\n",
        "\n",
        "Because we are dealing with 2 classes, the output layer can be constructed in\n",
        "two different ways:\n",
        "1. Single unit with a `\"sigmoid\"` nonlinearity. The loss must be `\"binary_crossentropy\"`.\n",
        "2. Two units (one for each class) and a `\"softmax\"` nonlinearity. The loss must be `\"sparse_categorical_crossentropy\"`.\n",
        "\n",
        "In this example, we choose the first option, which is what you would usually\n",
        "do for binary classification. The second option is usually reserved for when\n",
        "you have >2 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS97y5OAvoxi"
      },
      "source": [
        "from tensorflow import keras"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6YrdtoXvoxl"
      },
      "source": [
        "def get_clf(meta, hidden_layer_sizes, dropout):\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "    n_classes_ = meta[\"n_classes_\"]\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
        "        model.add(keras.layers.Dropout(dropout))\n",
        "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g-7ru5dvoxo"
      },
      "source": [
        "### Defining and training the neural net classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzswcGamvoxo"
      },
      "source": [
        "We use `KerasClassifier` because we're dealing with a classifcation task. The first argument should be a callable returning a `Keras.Model`, in this case, `get_clf`. As additional arguments, we pass the number of loss function (required) and the optimizer, but the later is optional. We must also pass all of the arguments to `get_clf` as keyword arguments to `KerasClassifier` if they don't have a default value in `get_clf`. Note that if you do not pass an argument to `KerasClassifier`, it will not be avilable for hyperparameter tuning. Finally, we also pass `random_state=0` for reproducible results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C83MtFdIvoxp"
      },
      "source": [
        "from scikeras.wrappers import KerasClassifier"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AEHN7jrvoxr"
      },
      "source": [
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(100,),\n",
        "    dropout=0.5,\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0uSTuc-voxu"
      },
      "source": [
        "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "V5MfyQuPvoxu",
        "outputId": "222d1045-8324-4e24-e469-5e2795a85da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "clf.fit(X, y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.9342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasClassifier(\n",
              "\tmodel=<function get_clf at 0x7fceea7a92f0>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=binary_crossentropy\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\thidden_layer_sizes=(100,)\n",
              "\tdropout=0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjguWBwFvoxx"
      },
      "source": [
        "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKn0yjAhvoxx"
      },
      "source": [
        "### Making predictions, classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCigf27Nvoxy",
        "outputId": "ecf36972-682f-4ee0-c813-1fc1502e3aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "y_pred = clf.predict(X[:5])\n",
        "y_pred"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScEtja89vox1",
        "outputId": "477ec90d-aae7-4c71-db97-a906f14f457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "y_proba = clf.predict_proba(X[:5])\n",
        "y_proba"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5656425 , 0.4343575 ],\n",
              "       [0.6093223 , 0.3906777 ],\n",
              "       [0.5853057 , 0.4146943 ],\n",
              "       [0.8011669 , 0.19883308],\n",
              "       [0.6443313 , 0.35566872]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP0awysQvox4"
      },
      "source": [
        "## Training a regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDjfhVS1vox4"
      },
      "source": [
        "### A toy regression task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCte_weqvox5"
      },
      "source": [
        "from sklearn.datasets import make_regression"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23zcHqu0vox7"
      },
      "source": [
        "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZSud7CGzvox9",
        "outputId": "2a2606fd-b6d4-47b6-92d1-1e4cce651438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 20), (1000,), -649.0148244404172, 615.4505181286091)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Q3et0GvoyA"
      },
      "source": [
        "### Definition of the `Keras` regression `Model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3u4aUY3voyA"
      },
      "source": [
        "Again, define a vanilla neural network. The main difference is that the output layer always has a single unit and does not apply any nonlinearity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHVZaSLvoyB"
      },
      "source": [
        "def get_reg(meta, hidden_layer_sizes, dropout):\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
        "        model.add(keras.layers.Dropout(dropout))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8RlOmEEvoyD"
      },
      "source": [
        "### Defining and training the neural net regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RNbMH4voyE"
      },
      "source": [
        "Training a regressor is almost the same as training a classifier. Mainly, we use `KerasRegressor` instead of `KerasClassifier` (this is the same terminology as in `sklearn`). We also change the loss function to `KerasRegressor.r_squared`. SciKeras provides this loss function because most of the `sklearn` ecosystem expects `R^2` as the loss function, but Keras does not have a default implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xls2GLLdvoyE"
      },
      "source": [
        "from scikeras.wrappers import KerasRegressor"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93o4AR0voyG"
      },
      "source": [
        "reg = KerasRegressor(\n",
        "    model=get_reg,\n",
        "    loss=KerasRegressor.r_squared,\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(100,),\n",
        "    dropout=0.5,\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYhLiboKvoyJ",
        "outputId": "ada0c251-7df3-4398-8ae6-3e82e2d6908f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "reg.fit(X_regr, y_regr)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: -0.0207\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasRegressor(\n",
              "\tmodel=<function get_reg at 0x7fceea7a9488>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=<function KerasRegressor.r_squared at 0x7fceeb4e2620>\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\thidden_layer_sizes=(100,)\n",
              "\tdropout=0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXEjq7GvoyL"
      },
      "source": [
        "### Making predictions, regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQzOT6u8voyL"
      },
      "source": [
        "You may call `predict` or `predict_proba` on the fitted model. For regressions, both methods return the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j83fCr3voyM",
        "outputId": "92ba8815-23e9-4adb-acd5-1d9f8e238064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred = reg.predict(X_regr[:5])\n",
        "y_pred"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.52893007,  0.87371266, -0.02472919,  0.14250527, -0.30587369])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3HsAnkvvoyN"
      },
      "source": [
        "## Saving and loading a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh9vJkhLvoyO"
      },
      "source": [
        "Save and load either the whole model by using pickle, or use Keras' specialized save methods on the `KerasClassifier.model_` or `KerasRegressor.model_` attribute that is created after fitting. You will want to use Keras' model saving utilities if any of the following apply:\n",
        "1. You wish to save only the weights or only the training configuration of your model.\n",
        "2. You wish to share your model with collaborators. Pickle is a relatively unsafe protocol and it is not recommended to share or load pickle objects publically.\n",
        "3. You care about performance, especially if doing in-memory serialization.\n",
        "\n",
        "For more information, see Keras' [saving documentation](https://www.tensorflow.org/guide/keras/save_and_serialize)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLwHH8uSvoyO"
      },
      "source": [
        "### Saving the whole model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3J714wuvoyP"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vtJFKzvoyS"
      },
      "source": [
        "bytes_model = pickle.dumps(reg)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcJt6U-voyU",
        "outputId": "9efca81a-d69f-4c23-cf31-3e97969fce0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "new_reg = pickle.loads(bytes_model)\n",
        "new_reg"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasRegressor(\n",
              "\tmodel=<function get_reg at 0x7fceea7a9488>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=<function KerasRegressor.r_squared at 0x7fceeb4e2620>\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\thidden_layer_sizes=(100,)\n",
              "\tdropout=0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zToyA37WvoyV"
      },
      "source": [
        "### Saving using Keras' saving methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI5Su_AnvoyW"
      },
      "source": [
        "This efficiently and safely saves the model to disk, including trained weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nvy_H-jvoyW",
        "outputId": "5ad63fe6-58e5-4a4d-9041-1efb50302b6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Save to disk\n",
        "reg.model_.save(\"/tmp/my_model\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/my_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmkr7_FmvoyY"
      },
      "source": [
        "# Load the model back into memory\n",
        "new_reg_model = keras.models.load_model(\"/tmp/my_model\")\n",
        "# Now we need to instantiate a new SciKeras object with this model\n",
        "reg = KerasRegressor(\n",
        "    new_reg_model,\n",
        "    loss=KerasRegressor.r_squared,\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(100,),\n",
        "    dropout=0.5,\n",
        "    random_state=0\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQY-WHYKvoyb"
      },
      "source": [
        "## Usage with an `sklearn Pipeline`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9FYNKejvoyb"
      },
      "source": [
        "It is possible to put the `KerasClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoLLPLczvoyc"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXE-c64voyd"
      },
      "source": [
        "pipe = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('clf', clf),\n",
        "])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpV2gbT_voyf",
        "outputId": "3f093c62-bd6f-40aa-c80d-325394186b99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "pipe.fit(X, y)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7180\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('clf',\n",
              "                 KerasClassifier(batch_size=None, build_fn=None, callbacks=None, dropout=0.5, epochs=1, hidden_layer_sizes=(100,), loss='binary_crossentropy', metrics=None, model=<function get_clf at 0x7fceea7a92f0>, optimizer='adam', random_state=None, run_eagerly=False, shuffle=True, validation_split=0.0, verbose=1, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXd85UIvoyi",
        "outputId": "d88d82be-5d1a-42fc-e774-03b7216f5c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y_proba = pipe.predict_proba(X[:5])\n",
        "y_proba"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.25762576, 0.74237424],\n",
              "       [0.5406221 , 0.45937788],\n",
              "       [0.5918224 , 0.40817758],\n",
              "       [0.6329869 , 0.3670131 ],\n",
              "       [0.5921637 , 0.40783632]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsWBdbn1voyj"
      },
      "source": [
        "To save the whole pipeline, including the Keras model, use `pickle`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJL15JWvoyk"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwFjnSynvoyk"
      },
      "source": [
        "Adding a new callback to the model is straightforward. Below we show how to add an `EarlyStopping` callback to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO-BGgG_voyn"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', patience=200, verbose=1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-WOjFWKvoyp"
      },
      "source": [
        "We now generate a toy dataset using `sklearn.datasets.make_moons`. This dataset was chosen specifically to trigger early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzEOe28R4U2N"
      },
      "source": [
        "from sklearn.datasets import make_moons"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRFbt-vi4Rl6",
        "outputId": "aac0eaa1-3012-4202-963e-6d5d5629cf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
        "X.shape, y.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 2), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmnYK4WTlFkr"
      },
      "source": [
        "We will first check fitting without the callback and then with. We will compare the training time and final accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbHXry8lLqI"
      },
      "source": [
        "import time"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_FIvTq9voyp",
        "outputId": "8761e596-f742-410b-e929-d7dff017da98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# First test without the callback\n",
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(500,),\n",
        "    dropout=0.5,\n",
        "    metrics=[\"binary_accuracy\"],\n",
        "    fit__validation_split=0.2,\n",
        "    epochs=4000,\n",
        "    verbose=False,\n",
        ")\n",
        "start = time.time()\n",
        "clf.fit(X, y)\n",
        "print(f\"Training time: {time.time() - start}\")\n",
        "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1][-1]}\")  # get last value of last fit/partial_fit call"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 71.7183313369751\n",
            "Final accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIUHrEOulU5_",
        "outputId": "8de23c48-d1d6-49ae-f775-a83c2e6e87ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test with the callback\n",
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(500,),\n",
        "    dropout=0.5,\n",
        "    metrics=[\"binary_accuracy\"],\n",
        "    fit__validation_split=0.2,\n",
        "    epochs=4000,\n",
        "    verbose=False,\n",
        "    callbacks=[es]\n",
        ")\n",
        "start = time.time()\n",
        "clf.fit(X, y)\n",
        "print(f\"Training time: {time.time() - start}\")\n",
        "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1][-1]}\")  # get last value of last fit/partial_fit call"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00217: early stopping\n",
            "Training time: 4.529699802398682\n",
            "Final accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_dtdHPSvoyu"
      },
      "source": [
        "For information on how to write custom callbacks, have a look at the \n",
        "\n",
        "---\n",
        "\n",
        "[Advanced_Usage](https://nbviewer.jupyter.org/github/adriangb/scikeras/blob/master/notebooks/Advanced_Usage.ipynb) notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_-sWsNvoyv"
      },
      "source": [
        "## Usage with sklearn `GridSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZytpOrjvoyv"
      },
      "source": [
        "### Special prefixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-KCDMhavoyv"
      },
      "source": [
        "SciKeras allows to direct access to all parameters passed to the wrapper constructors, including deeply nested routed parameters. This allows tunning of\n",
        "paramters like `hidden_layer_sizes` as well as `optimizer__learning_rate`.\n",
        "\n",
        "This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78M4fi78voyw"
      },
      "source": [
        "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZReurM2voyw"
      },
      "source": [
        "To differentiate paramters like `callbacks` which are accepted by both `tf.keras.Model.fit` and `tf.keras.Model.predict` you can add a `fit__` or `predict__` routing suffix respectively. Similar, the `model__` prefix may be used to specify that a paramter is destined only for `get_clf`/`get_reg` (or whatever callable you pass as your `model` argument).\n",
        "\n",
        "For more information on parameter routing with special prefixes, see the [Advanced Usage Docs](https://scikeras.org.readthedocs.build/en/latest/advanced.html#routed-parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZUxcDDvoyz"
      },
      "source": [
        "### Performing a grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEBmCKMtvoyz"
      },
      "source": [
        "Below we show how to perform a grid search over the learning rate (`optimizer__lr`), the model's number of hidden layers (`model__hidden_layer_sizes`), the model's dropout rate (`model__dropout`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07M8iQFBvoy0"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UuvOLT_voy1"
      },
      "source": [
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    optimizer__lr=0.1,\n",
        "    model__hidden_layer_sizes=(100,),\n",
        "    model__dropout=0.5,\n",
        "    verbose=False,\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NaBkHyBvoy3"
      },
      "source": [
        "*Note*: We set the verbosity level to zero (`verbose=False`) to prevent too much print output from being shown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABVjFkmnvoy3"
      },
      "source": [
        "params = {\n",
        "    'optimizer__lr': [0.05, 0.1],\n",
        "    'model__hidden_layer_sizes': [(100, ), (50, 50, ), (33, 33, 33, )],\n",
        "    'model__dropout': [0, 0.5],\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8MICSORvoy5"
      },
      "source": [
        "gs = GridSearchCV(clf, params, refit=False, cv=3, scoring='accuracy', verbose=2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GQnzOsGvoy8",
        "outputId": "a2d0a41e-dca1-452e-9c73-3a92c19e8fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gs.fit(X, y)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.7s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee4057488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedc3c6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 661 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedd72e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee40022f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fceda07b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9f66378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9f662f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9e15268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9ec1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9ce7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9c9eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9c9e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9b06c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced39ce6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced29329d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced295d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced1811ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9f17ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.8s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedd787bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9e35d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9ce78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9e15400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedd72eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedc3c68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedefe9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedd7150d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedaa62a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced3184048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9acb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9bc9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9f9ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9a3fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced69ebf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced5919950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced69eb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced481aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced28f3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee37607b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.05, total=   0.8s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9a3f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9bc9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9a3fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9b427b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9f9e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcee192b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9b42510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedd72e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9df3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fceda0dca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9f17c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced481ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.05, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced17b9048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced69ebd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced479a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced590b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fceda0dcd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced47497b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(50, 50), optimizer__lr=0.1, total=   0.5s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced3ef9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced58bc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.9s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced4749a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced5965840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9e15bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced589c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.05, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced481a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedd7657b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fced9df3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcedc3c6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n",
            "[CV] model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1 \n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_train_function.<locals>.train_function at 0x7fcedaa62f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fced9b420d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV]  model__dropout=0.5, model__hidden_layer_sizes=(33, 33, 33), optimizer__lr=0.1, total=   0.6s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:   21.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=KerasClassifier(batch_size=None, build_fn=None, callbacks=None, epochs=1, loss='binary_crossentropy', metrics=None, model=<function get_clf at 0x7fceea7a92f0>, model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer='adam', optimizer__lr=0.1, random_state=None, run_eagerly=False, shuffle=True, validation_split=0.0, verbose=False, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'model__dropout': [0, 0.5],\n",
              "                         'model__hidden_layer_sizes': [(100,), (50, 50),\n",
              "                                                       (33, 33, 33)],\n",
              "                         'optimizer__lr': [0.05, 0.1]},\n",
              "             pre_dispatch='2*n_jobs', refit=False, return_train_score=False,\n",
              "             scoring='accuracy', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UQHjLAoWvoy-",
        "outputId": "a5b7b0aa-71ef-44b9-c00e-2565459fc937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(gs.best_score_, gs.best_params_)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8900772430184194 {'model__dropout': 0, 'model__hidden_layer_sizes': (50, 50), 'optimizer__lr': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ZpLtKvvoy_"
      },
      "source": [
        "Of course, we could further nest the `KerasClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `clf__model__hidden_layer_sizes`)."
      ]
    }
  ]
}