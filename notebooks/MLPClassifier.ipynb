{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "Basic_Usage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22BE9uhvoxO"
      },
      "source": [
        "# MLPClassifier in SciKeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hapoJed-voxP"
      },
      "source": [
        "SciKeras is a bridge between Keras and Scikit-Learn. As such, one of SciKeras' design goals is to be able to create a Scikit-Learn style estimator backed by Keras. \n",
        "\n",
        "This notebook implements an estimator that is analogous to `sklearn.neural_network.MLPClassifier` using Keras. This estimator should (for the most part) work as a drop-in replacement for `MLPClassifier`!\n",
        "\n",
        "<table align=\"left\"><td>\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipyn\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
        "</td><td>\n",
        "<a target=\"_blank\" href=\"https://github.com/adriangb/scikeras/blob/master/notebooks/Basic_Usage.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iT-ibpi7voxQ"
      },
      "source": [
        "### Table of contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekJWKPFMvoxR"
      },
      "source": [
        "* [Defining the Keras Model](#Defining-the-Keras-Model)\n",
        "  * [Inputs](#Inputs)\n",
        "  * [Hidden layers](#Hidden-layers)\n",
        "  * [Output layers](#Training-the-neural-net-classifier)\n",
        "  * [Losses and optimizer](#Losses-and-optimizer)\n",
        "  * [Wrapping with SciKeras](#Wrapping-with-scikeras)\n",
        "* [Testing Classifier](#Testing-our-classifier)\n",
        "* [Self contained classifier](#Self-contained-classifier)\n",
        "  * [Subclassing](#Subclassing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6avb3GBQDQyG"
      },
      "source": [
        "Install SciKeras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcyTjVkvoxR"
      },
      "source": [
        "!python -m pip install git+https://github.com/adriangb/scikeras.git@master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/adriangb/scikeras.git@master\n",
            "  Cloning https://github.com/adriangb/scikeras.git (to revision master) to /private/var/folders/qx/54cwp9996s77rb4ng5j8y_v8zmmjlk/T/pip-req-build-y54w13qa\n",
            "  Running command git clone -q https://github.com/adriangb/scikeras.git /private/var/folders/qx/54cwp9996s77rb4ng5j8y_v8zmmjlk/T/pip-req-build-y54w13qa\n",
            "  Installing build dependencies ... \u001b[?25l^C\n",
            "\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
            "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.3 is available.\n",
            "You should consider upgrading via the '/Users/adrian.badaracco/Documents/GitHub/scikeras/.venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZveNcetDQyL"
      },
      "source": [
        "Silence TensorFlow logging to keep output succint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekNmO_GPDQyL"
      },
      "source": [
        "from tensorflow import get_logger\n",
        "get_logger().setLevel('ERROR')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf4j-x4DvoxV"
      },
      "source": [
        "from typing import Dict, Iterable, Any\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
        "from tensorflow import keras"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCuOBH8AvoxX"
      },
      "source": [
        "## Defining the Keras Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3fAUKBUvoxY"
      },
      "source": [
        "First, we outline our model building function, using a `Sequential` Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_clf_model():\n",
        "    model = keras.Sequential()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5vMC8ZYvoxY"
      },
      "source": [
        "### Inputs"
      ]
    },
    {
      "source": [
        "We need to define an input layer for Keras. SciKeras allows you to dynamically determine the input size based on the features (`X`). To do this, you need to add the `meta` parameter to `get_clf_model`'s parameters. `meta` will be a dictionary with all of the `meta` attributes that `KerasClassifier` generates during the `fit` call, including `n_features_in_`, which we will use to dynamically size the input layer."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmiOhALIvoxZ"
      },
      "source": [
        "def get_clf_model(meta: dict):\n",
        "    model = keras.Sequential()\n",
        "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
        "    model.add(inp)\n",
        "    return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPy_6ZDjvoxh"
      },
      "source": [
        "### Hidden Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BQ6Afd-voxh"
      },
      "source": [
        "Multilayer perceptrons are generally composed of an input layer, an output layer and 0 or more hidden layers. The size of the hidden layers is specified via the `hidden_layer_sizes` parameter in MLClassifier, where the the ith element represents the number of neurons in the ith hidden layer. Let's add that parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS97y5OAvoxi"
      },
      "source": [
        "def get_clf_model(hidden_layer_sizes: Iterable[int], meta: dict):\n",
        "    model = keras.Sequential()\n",
        "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
        "    model.add(inp)\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        layer = keras.layers.Dense(hidden_layer_size, activation=\"relu\")\n",
        "        model.add(layer)\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "source": [
        "### Output layers"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "The output layer needs to reflect the type of classification task being performed. Here, we will handle 2 cases:\n",
        "* binary classification: single output unit with sigmoid activation\n",
        "* multiclass classification: one output unit for each class, with softmax activation\n",
        "The main complication arises from determining which one to use. Like with the input features, SciKeras provides useful information on the target within the `meta` parameter. Specifically, we will use the `n_classes_` and `target_type_` attributes to determine the number of output units and activation function."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6YrdtoXvoxl"
      },
      "source": [
        "def get_clf_model(hidden_layer_sizes: Iterable[int], meta: dict):\n",
        "    model = keras.Sequential()\n",
        "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
        "    model.add(inp)\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        layer = keras.layers.Dense(hidden_layer_size, activation=\"relu\")\n",
        "        model.add(layer)\n",
        "    if meta[\"target_type_\"] == \"binary\":\n",
        "        n_output_units = 1\n",
        "        output_activation = \"sigmoid\"\n",
        "    elif meta[\"target_type_\"] == \"multiclass\":\n",
        "        n_output_units = meta[\"n_classes_\"]\n",
        "        output_activation = \"softmax\"\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Unsupported task type: {meta['target_type_']}\")\n",
        "    out = keras.layers.Dense(n_output_units, activation=output_activation)\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "source": [
        "For now, we raise a `NotImplementedError` for other target types. For an example handling multi-output target types, see the [Multi Output notebook](https://colab.research.google.com/github/adriangb/scikeras/blob/master/notebooks/MultiInput.ipynb)."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g-7ru5dvoxo"
      },
      "source": [
        "### Losses and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzswcGamvoxo"
      },
      "source": [
        "Like the output layer, the loss must match the type of classification task. Generally, it is easier and safet to allow SciKeras to compile your model for you by passing the loss to `KerasClassifier` directly (`KerasClassifier(loss=\"binary_crossentropy\")`). However, in order to implement custom logic around the choice of loss function, we compile the model ourselves within `get_clf_model`; SciKeras will not re-compile the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C83MtFdIvoxp"
      },
      "source": [
        "def get_clf_model(hidden_layer_sizes: Iterable[int], meta: dict):\n",
        "    model = keras.Sequential()\n",
        "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
        "    model.add(inp)\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        layer = keras.layers.Dense(hidden_layer_size, activation=\"relu\")\n",
        "        model.add(layer)\n",
        "    if meta[\"target_type_\"] == \"binary\":\n",
        "        n_output_units = 1\n",
        "        output_activation = \"sigmoid\"\n",
        "        loss = \"binary_crossentropy\"\n",
        "    elif meta[\"target_type_\"] == \"multiclass\":\n",
        "        n_output_units = meta[\"n_classes_\"]\n",
        "        output_activation = \"softmax\"\n",
        "        loss = \"sparse_categorical_crossentropy\"\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Unsupported task type: {meta['target_type_']}\")\n",
        "    out = keras.layers.Dense(n_output_units, activation=output_activation)\n",
        "    model.compile(loss=loss)\n",
        "    return model"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "source": [
        "At this point, we have a valid, compiled model. However if we want to be able to tune the optimizer, we should accept `compile_kwargs` as a parameter in `get_clf_model`. `compile_kwargs` will be a dictionary containing valid `kwargs` for `Model.compile`, so we can unpack it directly like `model.compile(**compile_kwargs)`. In this case however, we will only be taking the `optimizer` kwarg."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AEHN7jrvoxr"
      },
      "source": [
        "def get_clf_model(hidden_layer_sizes: Iterable[int], meta: Dict[str, Any], compile_kwargs: Dict[str, Any]):\n",
        "    model = keras.Sequential()\n",
        "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
        "    model.add(inp)\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        layer = keras.layers.Dense(hidden_layer_size, activation=\"relu\")\n",
        "        model.add(layer)\n",
        "    if meta[\"target_type_\"] == \"binary\":\n",
        "        n_output_units = 1\n",
        "        output_activation = \"sigmoid\"\n",
        "        loss = \"binary_crossentropy\"\n",
        "    elif meta[\"target_type_\"] == \"multiclass\":\n",
        "        n_output_units = meta[\"n_classes_\"]\n",
        "        output_activation = \"softmax\"\n",
        "        loss = \"sparse_categorical_crossentropy\"\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Unsupported task type: {meta['target_type_']}\")\n",
        "    out = keras.layers.Dense(n_output_units, activation=output_activation)\n",
        "    model.compile(loss=loss, optimizer=compile_kwargs[\"optimizer\"])\n",
        "    return model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "source": [
        "### Wrapping with SciKeras"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Our last step in defining our model is to wrap it with SciKeras. A couple of things to note are:\n",
        "* Every user-defined parameter in `model`/`get_clf_model` (in our case just `hidden_layer_sizes`) must be defined as a keyword argument to `KerasClassifier` with a default value.\n",
        "* Keras defaults to `\"rmsprop\"` for `optimizer`. We set it to `\"adam\"` to mimic MLPClassifier.\n",
        "* We set the learning rate for the optimizer to `0.001`, again to mimic MLPClassifier. We set this parameter using [parameter routing](https://scikeras.readthedocs.io/en/latest/advanced.html#routed-parameters).\n",
        "* Other parameters, such as `activation`, can be added similar to `hidden_layer_sizes`, but we omit them here for simplicity."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = KerasClassifier(\n",
        "    model=get_clf_model,\n",
        "    hidden_layer_sizes=(100, ),\n",
        "    optimizer=\"adam\",\n",
        "    optimizer__learning_rate=0.001,\n",
        ")"
      ]
    },
    {
      "source": [
        "## Testing our classifier"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0uSTuc-voxu"
      },
      "source": [
        "Before continouing, we will run a small test to make sure we get somewhat reasonable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "V5MfyQuPvoxu",
        "outputId": "9f609152-2b48-4e0d-f8dc-1675e151969d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "X, y = make_classification()\n",
        "\n",
        "# check that fit works\n",
        "clf.fit(X, y)\n",
        "clf.predict(X)\n",
        "# check cross-validation score\n",
        "# cross_val_score(clf, X, y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 1ms/step - loss: 4.7944\n",
            "4/4 [==============================] - 0s 982us/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "y should be a 1d array, got an array of shape (100, 100) instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-056a554d0511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# check that fit works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# check cross-validation score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# cross_val_score(clf, X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/scikeras/scikeras/wrappers.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;31m# post process y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/scikeras/scikeras/wrappers.py\u001b[0m in \u001b[0;36mpostprocess_y\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                         \u001b[0;31m# Appease the demands of sklearn transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m                         \u001b[0my_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m                     \u001b[0mclass_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 if (\n\u001b[1;32m   1007\u001b[0m                     \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/scikeras/.venv/lib/python3.8/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \"\"\"\n\u001b[1;32m    152\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# inverse transform of empty array is empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/scikeras/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/scikeras/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0;34m\"y should be a 1d array, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (100, 100) instead."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjguWBwFvoxx"
      },
      "source": [
        "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKn0yjAhvoxx"
      },
      "source": [
        "### Making predictions, classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCigf27Nvoxy",
        "outputId": "9f87d699-1e21-4f3a-ab97-09f9515f8cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred = clf.predict(X[:5])\n",
        "y_pred"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScEtja89vox1",
        "outputId": "8d15bcb5-9b98-4428-c7d3-7152e234e53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y_proba = clf.predict_proba(X[:5])\n",
        "y_proba"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5358717 , 0.46412832],\n",
              "       [0.6633073 , 0.3366927 ],\n",
              "       [0.71149606, 0.28850394],\n",
              "       [0.8953113 , 0.1046887 ],\n",
              "       [0.7850856 , 0.21491438]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP0awysQvox4"
      },
      "source": [
        "## Training a regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDjfhVS1vox4"
      },
      "source": [
        "### A toy regression task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCte_weqvox5"
      },
      "source": [
        "from sklearn.datasets import make_regression"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23zcHqu0vox7"
      },
      "source": [
        "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZSud7CGzvox9",
        "outputId": "19247832-e197-4052-ea55-2a0d45d19397",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 20), (1000,), -649.0148244404172, 615.4505181286091)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9Q3et0GvoyA"
      },
      "source": [
        "### Definition of the `Keras` regression `Model`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3u4aUY3voyA"
      },
      "source": [
        "Again, define a vanilla neural network. The main difference is that the output layer always has a single unit and does not apply any nonlinearity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSHVZaSLvoyB"
      },
      "source": [
        "def get_reg(meta, hidden_layer_sizes, dropout):\n",
        "    n_features_in_ = meta[\"n_features_in_\"]\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
        "    for hidden_layer_size in hidden_layer_sizes:\n",
        "        model.add(keras.layers.Dense(hidden_layer_size, activation=\"relu\"))\n",
        "        model.add(keras.layers.Dropout(dropout))\n",
        "    model.add(keras.layers.Dense(1))\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8RlOmEEvoyD"
      },
      "source": [
        "### Defining and training the neural net regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-RNbMH4voyE"
      },
      "source": [
        "Training a regressor is almost the same as training a classifier. Mainly, we use `KerasRegressor` instead of `KerasClassifier` (this is the same terminology as in `sklearn`). We also change the loss function to `KerasRegressor.r_squared`. SciKeras provides this loss function because most of the `sklearn` ecosystem expects `R^2` as the loss function, but Keras does not have a default implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xls2GLLdvoyE"
      },
      "source": [
        "from scikeras.wrappers import KerasRegressor"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i93o4AR0voyG"
      },
      "source": [
        "reg = KerasRegressor(\n",
        "    model=get_reg,\n",
        "    loss=KerasRegressor.r_squared,\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(100,),\n",
        "    dropout=0.5,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYhLiboKvoyJ",
        "outputId": "b9fedc24-5909-43af-f8b6-f11d94dc62a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "reg.fit(X_regr, y_regr)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: -0.0247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasRegressor(\n",
              "\tmodel=<function get_reg at 0x7f998ba1f488>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=<function KerasRegressor.r_squared at 0x7f998c756400>\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\thidden_layer_sizes=(100,)\n",
              "\tdropout=0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXEjq7GvoyL"
      },
      "source": [
        "### Making predictions, regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQzOT6u8voyL"
      },
      "source": [
        "You may call `predict` or `predict_proba` on the fitted model. For regressions, both methods return the same value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j83fCr3voyM",
        "outputId": "13b666a5-11ce-47df-fbd7-b96fad8c3890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_pred = reg.predict(X_regr[:5])\n",
        "y_pred"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.16403273, -0.36295909,  0.50139022, -0.062492  , -0.42927906])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3HsAnkvvoyN"
      },
      "source": [
        "## Saving and loading a model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh9vJkhLvoyO"
      },
      "source": [
        "Save and load either the whole model by using pickle, or use Keras' specialized save methods on the `KerasClassifier.model_` or `KerasRegressor.model_` attribute that is created after fitting. You will want to use Keras' model saving utilities if any of the following apply:\n",
        "1. You wish to save only the weights or only the training configuration of your model.\n",
        "2. You wish to share your model with collaborators. Pickle is a relatively unsafe protocol and it is not recommended to share or load pickle objects publically.\n",
        "3. You care about performance, especially if doing in-memory serialization.\n",
        "\n",
        "For more information, see Keras' [saving documentation](https://www.tensorflow.org/guide/keras/save_and_serialize)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLwHH8uSvoyO"
      },
      "source": [
        "### Saving the whole model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3J714wuvoyP"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6vtJFKzvoyS"
      },
      "source": [
        "bytes_model = pickle.dumps(reg)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWcJt6U-voyU",
        "outputId": "9c442382-86b5-43c6-98cd-3142be85abb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "new_reg = pickle.loads(bytes_model)\n",
        "new_reg"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KerasRegressor(\n",
              "\tmodel=<function get_reg at 0x7f998ba1f488>\n",
              "\tbuild_fn=None\n",
              "\twarm_start=False\n",
              "\trandom_state=None\n",
              "\toptimizer=adam\n",
              "\tloss=<function KerasRegressor.r_squared at 0x7f998c756400>\n",
              "\tmetrics=None\n",
              "\tbatch_size=None\n",
              "\tverbose=1\n",
              "\tcallbacks=None\n",
              "\tvalidation_split=0.0\n",
              "\tshuffle=True\n",
              "\trun_eagerly=False\n",
              "\tepochs=1\n",
              "\thidden_layer_sizes=(100,)\n",
              "\tdropout=0.5\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zToyA37WvoyV"
      },
      "source": [
        "### Saving using Keras' saving methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI5Su_AnvoyW"
      },
      "source": [
        "This efficiently and safely saves the model to disk, including trained weights.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Nvy_H-jvoyW"
      },
      "source": [
        "# Save to disk\n",
        "reg.model_.save(\"/tmp/my_model\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rmkr7_FmvoyY",
        "outputId": "f0493590-deaf-4c6e-88ef-b29d15ce8249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Load the model back into memory\n",
        "new_reg_model = keras.models.load_model(\"/tmp/my_model\")\n",
        "# Now we need to instantiate a new SciKeras object with this model\n",
        "# Note that we no longer pass paramters like hidden_layer_sizes, those\n",
        "# are note \"fixed\"\n",
        "reg = KerasRegressor(\n",
        "    new_reg_model,\n",
        "    loss=KerasRegressor.r_squared,\n",
        "    optimizer=\"adam\",\n",
        ")\n",
        "reg.fit(X_regr, y_regr)\n",
        "reg.predict(X_regr[:5])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: -0.0315\n",
            "1/1 [==============================] - 0s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04418676, -0.11787903,  0.56504041, -0.10095135, -0.58096522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQY-WHYKvoyb"
      },
      "source": [
        "## Usage with an `sklearn Pipeline`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9FYNKejvoyb"
      },
      "source": [
        "It is possible to put the `KerasClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoLLPLczvoyc"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqXE-c64voyd"
      },
      "source": [
        "pipe = Pipeline([\n",
        "    ('scale', StandardScaler()),\n",
        "    ('clf', clf),\n",
        "])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpV2gbT_voyf",
        "outputId": "344c88d4-b8b0-4941-d4c3-0a5a672cdd7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "pipe.fit(X, y)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step - loss: 0.7432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scale',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('clf',\n",
              "                 KerasClassifier(batch_size=None, build_fn=None, callbacks=None, dropout=0.5, epochs=1, hidden_layer_sizes=(100,), loss='binary_crossentropy', metrics=None, model=<function get_clf at 0x7f998ba1f268>, optimizer='adam', random_state=None, run_eagerly=False, shuffle=True, validation_split=0.0, verbose=1, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CXd85UIvoyi",
        "outputId": "d6d0d8fd-d9b0-4b11-dfb5-90869378d55f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "y_proba = pipe.predict_proba(X[:5])\n",
        "y_proba"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5154557 , 0.48454428],\n",
              "       [0.55230534, 0.44769466],\n",
              "       [0.48315734, 0.51684266],\n",
              "       [0.6526959 , 0.34730408],\n",
              "       [0.63546836, 0.3645316 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsWBdbn1voyj"
      },
      "source": [
        "To save the whole pipeline, including the Keras model, use `pickle`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bJL15JWvoyk"
      },
      "source": [
        "## Callbacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwFjnSynvoyk"
      },
      "source": [
        "Adding a new callback to the model is straightforward. Below we show how to add an `EarlyStopping` callback to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO-BGgG_voyn"
      },
      "source": [
        "es = keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', mode='max', patience=200, verbose=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-WOjFWKvoyp"
      },
      "source": [
        "We now generate a toy dataset using `sklearn.datasets.make_moons`. This dataset was chosen specifically to trigger early stopping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzEOe28R4U2N"
      },
      "source": [
        "from sklearn.datasets import make_moons"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRFbt-vi4Rl6",
        "outputId": "30e66352-3d47-470f-8b44-449dac6f7bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
        "X.shape, y.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100, 2), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmnYK4WTlFkr"
      },
      "source": [
        "We will first check fitting without the callback and then with. We will compare the training time and final accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IbHXry8lLqI"
      },
      "source": [
        "import time"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_FIvTq9voyp",
        "outputId": "b001c8b8-89f8-4b9d-f535-2e1cd1e548c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# First test without the callback\n",
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(500,),\n",
        "    dropout=0.5,\n",
        "    metrics=[\"binary_accuracy\"],\n",
        "    fit__validation_split=0.2,\n",
        "    epochs=500,\n",
        "    verbose=False,\n",
        ")\n",
        "start = time.time()\n",
        "clf.fit(X, y)\n",
        "print(f\"Training time: {time.time() - start}\")\n",
        "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1][-1]}\")  # get last value of last fit/partial_fit call"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time: 10.489465475082397\n",
            "Final accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIUHrEOulU5_",
        "outputId": "05c9bd7f-795a-4bdb-f1f0-9f11514eacd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test with the callback\n",
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    hidden_layer_sizes=(500,),\n",
        "    dropout=0.5,\n",
        "    metrics=[\"binary_accuracy\"],\n",
        "    fit__validation_split=0.2,\n",
        "    epochs=500,\n",
        "    verbose=False,\n",
        "    callbacks=[es]\n",
        ")\n",
        "start = time.time()\n",
        "clf.fit(X, y)\n",
        "print(f\"Training time: {time.time() - start}\")\n",
        "print(f\"Final accuracy: {clf.history_['val_binary_accuracy'][-1][-1]}\")  # get last value of last fit/partial_fit call"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 00215: early stopping\n",
            "Training time: 4.222731351852417\n",
            "Final accuracy: 0.949999988079071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_dtdHPSvoyu"
      },
      "source": [
        "For information on how to write custom callbacks, have a look at the \n",
        "\n",
        "---\n",
        "\n",
        "[Advanced_Usage](https://nbviewer.jupyter.org/github/adriangb/scikeras/blob/master/notebooks/Advanced_Usage.ipynb) notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_-sWsNvoyv"
      },
      "source": [
        "## Usage with sklearn `GridSearchCV`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZytpOrjvoyv"
      },
      "source": [
        "### Special prefixes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-KCDMhavoyv"
      },
      "source": [
        "SciKeras allows to direct access to all parameters passed to the wrapper constructors, including deeply nested routed parameters. This allows tunning of\n",
        "paramters like `hidden_layer_sizes` as well as `optimizer__learning_rate`.\n",
        "\n",
        "This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78M4fi78voyw"
      },
      "source": [
        "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZReurM2voyw"
      },
      "source": [
        "To differentiate paramters like `callbacks` which are accepted by both `tf.keras.Model.fit` and `tf.keras.Model.predict` you can add a `fit__` or `predict__` routing suffix respectively. Similar, the `model__` prefix may be used to specify that a paramter is destined only for `get_clf`/`get_reg` (or whatever callable you pass as your `model` argument).\n",
        "\n",
        "For more information on parameter routing with special prefixes, see the [Advanced Usage Docs](https://scikeras.org.readthedocs.build/en/latest/advanced.html#routed-parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZUxcDDvoyz"
      },
      "source": [
        "### Performing a grid search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEBmCKMtvoyz"
      },
      "source": [
        "Below we show how to perform a grid search over the learning rate (`optimizer__lr`), the model's number of hidden layers (`model__hidden_layer_sizes`), the model's dropout rate (`model__dropout`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07M8iQFBvoy0"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UuvOLT_voy1"
      },
      "source": [
        "clf = KerasClassifier(\n",
        "    model=get_clf,\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    optimizer__lr=0.1,\n",
        "    model__hidden_layer_sizes=(100,),\n",
        "    model__dropout=0.5,\n",
        "    verbose=False,\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NaBkHyBvoy3"
      },
      "source": [
        "*Note*: We set the verbosity level to zero (`verbose=False`) to prevent too much print output from being shown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABVjFkmnvoy3"
      },
      "source": [
        "params = {\n",
        "    'optimizer__lr': [0.05, 0.1],\n",
        "    'model__hidden_layer_sizes': [(100, ), (50, 50, ), (33, 33, 33, )],\n",
        "    'model__dropout': [0, 0.5],\n",
        "}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8MICSORvoy5"
      },
      "source": [
        "gs = GridSearchCV(clf, params, scoring='accuracy', n_jobs=-1, verbose=True)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GQnzOsGvoy8",
        "outputId": "1d9afe71-2691-489b-9f02-a742605a9bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "gs.fit(X, y)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   18.5s\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   24.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=KerasClassifier(batch_size=None, build_fn=None, callbacks=None, epochs=1, loss='binary_crossentropy', metrics=None, model=<function get_clf at 0x7f998ba1f268>, model__dropout=0.5, model__hidden_layer_sizes=(100,), optimizer='adam', optimizer__lr=0.1, random_state=None, run_eagerly=False, shuffle=True, validation_split=0.0, verbose=False, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'model__dropout': [0, 0.5],\n",
              "                         'model__hidden_layer_sizes': [(100,), (50, 50),\n",
              "                                                       (33, 33, 33)],\n",
              "                         'optimizer__lr': [0.05, 0.1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UQHjLAoWvoy-",
        "outputId": "0c5e74e9-cc91-49af-f6a1-e04a285ad954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(gs.best_score_, gs.best_params_)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.86 {'model__dropout': 0, 'model__hidden_layer_sizes': (50, 50), 'optimizer__lr': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-ZpLtKvvoy_"
      },
      "source": [
        "Of course, we could further nest the `KerasClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `clf__model__hidden_layer_sizes`)."
      ]
    }
  ]
}