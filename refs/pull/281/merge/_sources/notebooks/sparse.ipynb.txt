{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9cd1cddd",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/adriangb/scikeras/blob/docs-deploy/refs/heads/master/notebooks/AutoEncoders.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3a1c7",
   "metadata": {},
   "source": [
    "# Sparse Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40d485",
   "metadata": {},
   "source": [
    "SciKeras supports sparse inputs (`X`/features).\n",
    "You don't have to do anything special for this to work, you can just pass a sparse matrix to `fit()`.\n",
    "\n",
    "In this notebook, we'll demonstrate how this works and compare memory consumption of sparse inputs to dense inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f0ba",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee45652",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:46.231438Z",
     "iopub.status.busy": "2022-07-22T23:36:46.231176Z",
     "iopub.status.idle": "2022-07-22T23:36:52.310232Z",
     "shell.execute_reply": "2022-07-22T23:36:52.309554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading memory_profiler-0.60.0.tar.gz (38 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: psutil in /home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages (from memory_profiler) (5.9.1)\r\n",
      "Building wheels for collected packages: memory_profiler\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for memory_profiler (setup.py) ... \u001b[?25l-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \b-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b \bdone\r\n",
      "\u001b[?25h  Created wheel for memory_profiler: filename=memory_profiler-0.60.0-py3-none-any.whl size=31267 sha256=25fd8bc50b6bbf77528eb51775bde258d8533b648df40ed484180e3d17196ec9\r\n",
      "  Stored in directory: /home/runner/.cache/pip/wheels/01/ca/8b/b518dd2aef69635ad6fcab87069c9c52f355a2e9c5d4c02da9\r\n",
      "Successfully built memory_profiler\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: memory_profiler\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed memory_profiler-0.60.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ff8bd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:52.314896Z",
     "iopub.status.busy": "2022-07-22T23:36:52.314111Z",
     "iopub.status.idle": "2022-07-22T23:36:54.472725Z",
     "shell.execute_reply": "2022-07-22T23:36:54.471664Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from tensorflow import get_logger\n",
    "get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setting the random state for TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35de6227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.477006Z",
     "iopub.status.busy": "2022-07-22T23:36:54.476366Z",
     "iopub.status.idle": "2022-07-22T23:36:54.491465Z",
     "shell.execute_reply": "2022-07-22T23:36:54.490593Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import scikeras\n",
    "except ImportError:\n",
    "    !python -m pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e419c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.496146Z",
     "iopub.status.busy": "2022-07-22T23:36:54.495348Z",
     "iopub.status.idle": "2022-07-22T23:36:54.906720Z",
     "shell.execute_reply": "2022-07-22T23:36:54.906107Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3fbc0a",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset we'll be using is designed to demostrate a worst-case/best-case scenario for dense and sparse input features respectively.\n",
    "It consists of a single categorical feature with equal number of categories as rows.\n",
    "This means the one-hot encoded representation will require as many columns as it does rows, making it very ineffienct to store as a dense matrix but very efficient to store as a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9155e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.916077Z",
     "iopub.status.busy": "2022-07-22T23:36:54.914838Z",
     "iopub.status.idle": "2022-07-22T23:36:54.920433Z",
     "shell.execute_reply": "2022-07-22T23:36:54.919900Z"
    }
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 20_000  # hand tuned to be ~4GB peak\n",
    "\n",
    "X = np.arange(0, N_SAMPLES).reshape(-1, 1)\n",
    "y = np.random.uniform(0, 1, size=(X.shape[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157dc46",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model here is nothing special, just a basic multilayer perceptron with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09bf834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.924949Z",
     "iopub.status.busy": "2022-07-22T23:36:54.923811Z",
     "iopub.status.idle": "2022-07-22T23:36:54.929249Z",
     "shell.execute_reply": "2022-07-22T23:36:54.928713Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_clf(meta) -> keras.Model:\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(n_features_in_,)))\n",
    "    # a single hidden layer\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9cb421",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Here is where it gets interesting.\n",
    "We make two Scikit-Learn pipelines that use `OneHotEncoder`: one that uses `sparse=False` to force a dense matrix as the output and another that uses `sparse=True` (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6fb8f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.933689Z",
     "iopub.status.busy": "2022-07-22T23:36:54.932550Z",
     "iopub.status.idle": "2022-07-22T23:36:54.938082Z",
     "shell.execute_reply": "2022-07-22T23:36:54.937535Z"
    }
   },
   "outputs": [],
   "source": [
    "dense_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", OneHotEncoder(sparse=False)),\n",
    "        (\"model\", KerasRegressor(get_clf, loss=\"mse\", epochs=5, verbose=False))\n",
    "    ]\n",
    ")\n",
    "\n",
    "sparse_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", OneHotEncoder(sparse=True)),\n",
    "        (\"model\", KerasRegressor(get_clf, loss=\"mse\", epochs=5, verbose=False))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e1f45",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "Our benchmark will be to just train each one of these pipelines and measure peak memory consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a71bc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:36:54.942493Z",
     "iopub.status.busy": "2022-07-22T23:36:54.941315Z",
     "iopub.status.idle": "2022-07-22T23:37:51.896413Z",
     "shell.execute_reply": "2022-07-22T23:37:51.895413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 3447.56 MiB, increment: 3066.52 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit dense_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad3ef574",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:37:51.903513Z",
     "iopub.status.busy": "2022-07-22T23:37:51.901981Z",
     "iopub.status.idle": "2022-07-22T23:38:07.314198Z",
     "shell.execute_reply": "2022-07-22T23:38:07.313336Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 660.63 MiB, increment: 74.79 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit sparse_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d41f9",
   "metadata": {},
   "source": [
    "You should see at least 100x more memory consumption **increment** in the dense pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a510052",
   "metadata": {},
   "source": [
    "### Runtime\n",
    "\n",
    "Using sparse inputs can have a drastic impact on memory usage, but it often (not always) hurts overall runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68d98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:38:07.318234Z",
     "iopub.status.busy": "2022-07-22T23:38:07.317896Z",
     "iopub.status.idle": "2022-07-22T23:44:45.330339Z",
     "shell.execute_reply": "2022-07-22T23:44:45.326002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.7 s ± 3.38 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit dense_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c66ba4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:44:45.363349Z",
     "iopub.status.busy": "2022-07-22T23:44:45.362181Z",
     "iopub.status.idle": "2022-07-22T23:46:51.255448Z",
     "shell.execute_reply": "2022-07-22T23:46:51.254751Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_20/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_22/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_24/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_26/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_14/dense_28/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_15/dense_30/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_32/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_17/dense_34/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.8 s ± 1.33 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sparse_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301f2ce",
   "metadata": {},
   "source": [
    "## Tensorflow Datasets\n",
    "\n",
    "Tensorflow provides a whole suite of functionality around the [Dataset].\n",
    "Datasets are lazily evaluated, can be sparse and minimize the transformations required to feed data into the model.\n",
    "They are _a lot_ more performant and efficient at scale than using numpy datastructures, even sparse ones.\n",
    "\n",
    "SciKeras does not (and cannot) support Datasets directly because Scikit-Learn itself does not support them and SciKeras' outwards API is Scikit-Learn's API.\n",
    "You may want to explore breaking out of SciKeras and just using TensorFlow/Keras directly to see if Datasets can have a large impact for your use case.\n",
    "\n",
    "[Dataset]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24697cf",
   "metadata": {},
   "source": [
    "## Bonus: dtypes\n",
    "\n",
    "You might be able to save even more memory by changing the output dtype of `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46d9a16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:46:51.267028Z",
     "iopub.status.busy": "2022-07-22T23:46:51.265403Z",
     "iopub.status.idle": "2022-07-22T23:46:51.288622Z",
     "shell.execute_reply": "2022-07-22T23:46:51.286678Z"
    }
   },
   "outputs": [],
   "source": [
    "sparse_pipline_uint8 = Pipeline(\n",
    "    [\n",
    "        (\"encoder\", OneHotEncoder(sparse=True, dtype=np.uint8)),\n",
    "        (\"model\", KerasRegressor(get_clf, loss=\"mse\", epochs=5, verbose=False))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0649f5db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-22T23:46:51.297105Z",
     "iopub.status.busy": "2022-07-22T23:46:51.296869Z",
     "iopub.status.idle": "2022-07-22T23:47:08.728736Z",
     "shell.execute_reply": "2022-07-22T23:47:08.727935Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/runner/work/scikeras/scikeras/.venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Reshape:0\", shape=(None, 100), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_18/dense_36/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 987.37 MiB, increment: 35.24 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit sparse_pipline_uint8.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
