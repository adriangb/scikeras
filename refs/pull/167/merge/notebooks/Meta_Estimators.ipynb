{
 "cells": [
  {
   "cell_type": "raw",
   "id": "dependent-extreme",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/adriangb/scikeras/blob/docs-deploy/refs/heads/master/notebooks/Meta_Estimators.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Run in Google Colab</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-philip",
   "metadata": {},
   "source": [
    "# Meta Estimators in SciKeras\n",
    "\n",
    "In this notebook, we implement sklearn ensemble and tree meta-estimators backed by a Keras MLP model.\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "* [1. Setup](#1.-Setup)\n",
    "* [2. Defining the Keras Model](#2.-Defining-the-Keras-Model)\n",
    "  * [2.1 Building a boosting ensemble](#2.1-Building-a-boosting-ensemble)\n",
    "* [3. Testing with a toy dataset](#3.-Testing-with-a-toy-dataset)\n",
    "* [4. Bagging ensemble](#4.-Bagging-ensemble)\n",
    "\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "utility-education",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:08.459287Z",
     "iopub.status.busy": "2021-01-31T07:27:08.458630Z",
     "iopub.status.idle": "2021-01-31T07:27:10.660302Z",
     "shell.execute_reply": "2021-01-31T07:27:10.661089Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import scikeras\n",
    "except ImportError:\n",
    "    !python -m pip install scikeras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-namibia",
   "metadata": {},
   "source": [
    "Silence TensorFlow logging to keep output succinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flush-marble",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:10.664989Z",
     "iopub.status.busy": "2021-01-31T07:27:10.663931Z",
     "iopub.status.idle": "2021-01-31T07:27:10.668941Z",
     "shell.execute_reply": "2021-01-31T07:27:10.669668Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tensorflow import get_logger\n",
    "get_logger().setLevel('ERROR')\n",
    "warnings.filterwarnings(\"ignore\", message=\"Setting the random state for TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-croatia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:10.672985Z",
     "iopub.status.busy": "2021-01-31T07:27:10.671933Z",
     "iopub.status.idle": "2021-01-31T07:27:11.356923Z",
     "shell.execute_reply": "2021-01-31T07:27:11.357394Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-elite",
   "metadata": {},
   "source": [
    "## 2. Defining the Keras Model\n",
    "\n",
    "We borrow our MLPClassifier implementation from the [MLPClassifier notebook](https://colab.research.google.com/github/adriangb/scikeras/blob/master/notebooks/MLPClassifier_and_MLPRegressor.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "meaning-wonder",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.366251Z",
     "iopub.status.busy": "2021-01-31T07:27:11.365598Z",
     "iopub.status.idle": "2021-01-31T07:27:11.377219Z",
     "shell.execute_reply": "2021-01-31T07:27:11.377691Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Iterable, Any\n",
    "\n",
    "\n",
    "def get_clf_model(hidden_layer_sizes: Iterable[int], meta: Dict[str, Any], compile_kwargs: Dict[str, Any]):\n",
    "    model = keras.Sequential()\n",
    "    inp = keras.layers.Input(shape=(meta[\"n_features_in_\"]))\n",
    "    model.add(inp)\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        layer = keras.layers.Dense(hidden_layer_size, activation=\"relu\")\n",
    "        model.add(layer)\n",
    "    if meta[\"target_type_\"] == \"binary\":\n",
    "        n_output_units = 1\n",
    "        output_activation = \"sigmoid\"\n",
    "        loss = \"binary_crossentropy\"\n",
    "    elif meta[\"target_type_\"] == \"multiclass\":\n",
    "        n_output_units = meta[\"n_classes_\"]\n",
    "        output_activation = \"softmax\"\n",
    "        loss = \"sparse_categorical_crossentropy\"\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported task type: {meta['target_type_']}\")\n",
    "    out = keras.layers.Dense(n_output_units, activation=output_activation)\n",
    "    model.add(out)\n",
    "    model.compile(loss=loss, optimizer=compile_kwargs[\"optimizer\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-secret",
   "metadata": {},
   "source": [
    "Next we wrap this Keras model with SciKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "driven-sewing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.383112Z",
     "iopub.status.busy": "2021-01-31T07:27:11.382038Z",
     "iopub.status.idle": "2021-01-31T07:27:11.386325Z",
     "shell.execute_reply": "2021-01-31T07:27:11.385825Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = KerasClassifier(\n",
    "    model=get_clf_model,\n",
    "    hidden_layer_sizes=(100, ),\n",
    "    optimizer=\"adam\",\n",
    "    optimizer__learning_rate=0.001,\n",
    "    verbose=0,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-therapy",
   "metadata": {},
   "source": [
    "### 2.1 Building a boosting ensemble\n",
    "\n",
    "Because SciKeras estimators are fully compliant with the Scikit-Learn API, we can make use of Scikit-Learn's built in utilities. In particular example, we will use `AdaBoostClassifier` from `sklearn.ensemble.AdaBoostClassifier`, but the process is the same for most Scikit-Learn meta-estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "further-sculpture",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.390493Z",
     "iopub.status.busy": "2021-01-31T07:27:11.389369Z",
     "iopub.status.idle": "2021-01-31T07:27:11.503588Z",
     "shell.execute_reply": "2021-01-31T07:27:11.504374Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "egyptian-earth",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.508028Z",
     "iopub.status.busy": "2021-01-31T07:27:11.506811Z",
     "iopub.status.idle": "2021-01-31T07:27:11.512660Z",
     "shell.execute_reply": "2021-01-31T07:27:11.511838Z"
    }
   },
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(base_estimator=clf, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-wilson",
   "metadata": {},
   "source": [
    "## 3. Testing with a toy dataset\n",
    "\n",
    "Before continouing, we will run a small test to make sure we get somewhat reasonable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affecting-interest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.519313Z",
     "iopub.status.busy": "2021-01-31T07:27:11.518718Z",
     "iopub.status.idle": "2021-01-31T07:27:11.569432Z",
     "shell.execute_reply": "2021-01-31T07:27:11.568569Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "selected-delight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:27:11.575458Z",
     "iopub.status.busy": "2021-01-31T07:27:11.574871Z",
     "iopub.status.idle": "2021-01-31T07:29:51.229299Z",
     "shell.execute_reply": "2021-01-31T07:29:51.228755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single score: 0.31\n",
      "AdaBoost score: 0.80\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons()\n",
    "\n",
    "single_score = np.mean(cross_val_score(clf, X, y))\n",
    "\n",
    "adaboost_score = np.mean(cross_val_score(adaboost, X, y))\n",
    "\n",
    "print(f\"Single score: {single_score:.2f}\")\n",
    "print(f\"AdaBoost score: {adaboost_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-playlist",
   "metadata": {},
   "source": [
    "We see that the score for the AdaBoost classifier is slightly higher than that of an individual MLPRegressor instance. We can explore the individual classifiers, and see that each one is composed of a Keras Model with it's own individual weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secret-sending",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:29:51.261840Z",
     "iopub.status.busy": "2021-01-31T07:29:51.261063Z",
     "iopub.status.idle": "2021-01-31T07:30:17.950408Z",
     "shell.execute_reply": "2021-01-31T07:30:17.951112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=KerasClassifier(hidden_layer_sizes=(100,), model=<function get_clf_model at 0x7faaf5515d30>, optimizer='adam', optimizer__learning_rate=0.001, random_state=0, verbose=0),\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost.fit(X, y)  # we need to fit outside of cross_val_score before accessing the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "turned-george",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:30:17.956338Z",
     "iopub.status.busy": "2021-01-31T07:30:17.955716Z",
     "iopub.status.idle": "2021-01-31T07:30:17.961995Z",
     "shell.execute_reply": "2021-01-31T07:30:17.961092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1261113   0.08298672 -0.08263937  0.17582898 -0.1499544 ]\n",
      "[ 0.0689153  -0.21101238  0.19630979 -0.07124205 -0.00968436]\n"
     ]
    }
   ],
   "source": [
    "print(adaboost.estimators_[0].model_.get_weights()[0][0, :5])  # first sub-estimator\n",
    "print(adaboost.estimators_[1].model_.get_weights()[0][0, :5])  # second sub-estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-spice",
   "metadata": {},
   "source": [
    "## 4. Bagging ensemble\n",
    "\n",
    "For comparison, we run the same test with an ensemble built using `sklearn.ensemble.BaggingClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "center-sword",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:30:17.966086Z",
     "iopub.status.busy": "2021-01-31T07:30:17.965474Z",
     "iopub.status.idle": "2021-01-31T07:30:17.968246Z",
     "shell.execute_reply": "2021-01-31T07:30:17.968707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "satisfied-vegetarian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-31T07:30:17.974254Z",
     "iopub.status.busy": "2021-01-31T07:30:17.973422Z",
     "iopub.status.idle": "2021-01-31T07:31:14.973305Z",
     "shell.execute_reply": "2021-01-31T07:31:14.972699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging score: 0.63\n"
     ]
    }
   ],
   "source": [
    "bagging = BaggingClassifier(base_estimator=clf, random_state=0, n_jobs=-1)\n",
    "\n",
    "bagging_score = np.mean(cross_val_score(bagging, X, y))\n",
    "\n",
    "print(f\"Bagging score: {bagging_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
